"""
ê°„ê²°í•˜ê³  ëª…í™•í•œ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸
"""

import pandas as pd
import numpy as np
import os
import joblib
from typing import Dict, List, Optional

from src.cv import stratified_kfold_split, kfold_split
from src.ensemble import train_stacking_ensemble, train_voting_ensemble, train_logistic_regression, evaluate_model
from src.preprocessing import load_data, preprocess_pipeline, feature_engineering_pipeline, drop_column


def run(
    df: pd.DataFrame,
    target_col: str = "Attrition_Binary",
    is_preprocess: bool = True,
    is_feature_engineering: bool = True,
    cv_strategy: str = 'stratified_kfold',  # 'stratified_kfold', 'kfold', None
    tuning_strategy: str = None,  # None, 'optuna', 'grid_search', 'random_search'
    ensemble_strategy: str = 'stacking',  # 'stacking', 'voting', 'logistic'
    is_save: bool = True,
) -> Dict:
    """
    ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    ğŸ’¡ í•µì‹¬ ê°œì„ :
    - íŠœë‹ì€ í•œ ë²ˆë§Œ ìˆ˜í–‰ (ì „ì²´ ë°ì´í„°ë¡œ)
    - CV í‰ê°€ëŠ” íŠœë‹ëœ íŒŒë¼ë¯¸í„°ë¡œ ìˆ˜í–‰
    """
    
    print(f"\n{'='*80}")
    print("ğŸš€ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print(f"{'='*80}\n")
    
    # 1ï¸âƒ£ ì „ì²˜ë¦¬
    print("1ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬...")
    if is_preprocess:
        df = preprocess_pipeline(df)
    else:
        df = drop_column(df)
    
    if is_feature_engineering:
        print("2Feature Engineering...")
        df = feature_engineering_pipeline(df)
    
    print(f"   âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {df.shape}")
    
    # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    features = df.drop(columns=[target_col]).columns.tolist()
    X_full = df[features]
    y_full = df[target_col]
    
    # 2ï¸âƒ£ íŠœë‹ (í•œ ë²ˆë§Œ!)
    tuned_params = None  # íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì €ì¥ìš©
    if tuning_strategy is not None:
        print(f"\n2ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ({tuning_strategy})")
        print("   âš¡ ì „ì²´ ë°ì´í„°ë¡œ í•œ ë²ˆë§Œ íŠœë‹...")
        
        # ì „ì²´ ë°ì´í„°ë¡œ íŠœë‹í•˜ì—¬ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°
        if ensemble_strategy == 'stacking':
            tuned_model, tuned_params = train_stacking_ensemble(
                X_full, y_full,
                cv_strategy=cv_strategy,
                tuning_strategy=tuning_strategy,
                n_trials=240,  # í•„ìš”ì‹œ ì¡°ì •
                return_params=True
            )
        elif ensemble_strategy == 'voting':
            tuned_model, tuned_params = train_voting_ensemble(
                X_full, y_full,
                cv_strategy=cv_strategy,
                tuning_strategy=tuning_strategy,
                n_trials=120,
                return_params=True
            )
        
        print("   âœ… íŠœë‹ ì™„ë£Œ! ìµœì  íŒŒë¼ë¯¸í„° ì°¾ìŒ")
    else:
        print(f"\n2ï¸âƒ£ íŠœë‹ ìŠ¤í‚µ (ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©)")
    
    # 3ï¸âƒ£ CV ì„¤ì •
    print(f"\n3ï¸âƒ£ CV ì „ëµ: {cv_strategy or 'ë‹¨ìˆœ ë¶„í• '}")
    if cv_strategy == 'stratified_kfold':
        folds = stratified_kfold_split(df, target_col=target_col, n_splits=5, shuffle=True, random_state=42)
    elif cv_strategy == 'kfold':
        folds = kfold_split(df, n_splits=5, shuffle=True, random_state=42)
    else:
        # CV ì—†ì´ ë‹¨ìˆœ ë¶„í• 
        from sklearn.model_selection import train_test_split
        train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[target_col], random_state=42)
        folds = [(train_df.index.tolist(), test_df.index.tolist())]
    
    # 4ï¸âƒ£ ê° í´ë“œì—ì„œ í‰ê°€ (íŠœë‹ ì•ˆ í•¨!)
    print(f"\n4ï¸âƒ£ ëª¨ë¸ í‰ê°€ (ê° í´ë“œ)")
    print(f"   ëª¨ë¸: {ensemble_strategy}")
    print(f"   {'âœ… íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©' if tuning_strategy else 'ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©'}\n")
    
    cv_results = []
    models = []
    
    for fold_num, (train_idx, val_idx) in enumerate(folds, 1):
        print(f"\n{'â”€'*60}")
        print(f"ğŸ“ Fold {fold_num}/{len(folds)}")
        print(f"{'â”€'*60}")
        
        # ë°ì´í„° ë¶„í• 
        X_train = df.loc[train_idx, features]
        y_train = df.loc[train_idx, target_col]
        X_val = df.loc[val_idx, features]
        y_val = df.loc[val_idx, target_col]
        
        # ëª¨ë¸ í•™ìŠµ (íŠœë‹ ì—†ì´!)
        if ensemble_strategy == 'stacking':
            model = train_stacking_ensemble(
                X_train, y_train,
                cv_strategy=cv_strategy,
                tuning_strategy=None,  # ğŸ‘ˆ íŠœë‹ ì•ˆ í•¨!
                best_params=tuned_params  # ğŸ‘ˆ íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš©
            )
        elif ensemble_strategy == 'voting':
            model = train_voting_ensemble(
                X_train, y_train,
                cv_strategy=cv_strategy,
                tuning_strategy=None,  # ğŸ‘ˆ íŠœë‹ ì•ˆ í•¨!
                best_params=tuned_params  # ğŸ‘ˆ íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš©
            )
        else:  # logistic
            model = train_logistic_regression(X_train, y_train)
        
        # í‰ê°€
        metrics = evaluate_model(
            model, X_val, y_val,
            fold_num=fold_num,
            n_splits=len(folds)
        )
        
        cv_results.append(metrics)
        models.append(model)
    
    # 5ï¸âƒ£ ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*80}")
    print("ğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½")
    print(f"{'='*80}")
    
    summary = {}
    for metric in cv_results[0].keys():
        values = [r[metric] for r in cv_results]
        summary[metric] = {
            'mean': np.mean(values),
            'std': np.std(values)
        }
        if summary[metric]['mean'] > 0:  # ROC-AUCê°€ 0ì´ë©´ ìŠ¤í‚µ
            print(f"{metric:12s}: {summary[metric]['mean']:.4f} Â± {summary[metric]['std']:.4f}")
    print(f"{'='*80}\n")
    
    if is_save:
        # 6ï¸âƒ£ ìµœì¢… ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°)
        print("6ï¸âƒ£ ìµœì¢… ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°)...")
        
        if ensemble_strategy == 'stacking':
            final_model = train_stacking_ensemble(
                X_full, y_full,
                cv_strategy=cv_strategy,
                tuning_strategy=None,  # ğŸ‘ˆ íŠœë‹ ì•ˆ í•¨
                best_params=tuned_params  # ğŸ‘ˆ íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš©
            )
        elif ensemble_strategy == 'voting':
            final_model = train_voting_ensemble(
                X_full, y_full,
                cv_strategy=cv_strategy,
                tuning_strategy=None,  # ğŸ‘ˆ íŠœë‹ ì•ˆ í•¨
                best_params=tuned_params  # ğŸ‘ˆ íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš©
            )
        else:
            final_model = train_logistic_regression(X_full, y_full)
    
    # 7ï¸âƒ£ ëª¨ë¸ ì €ì¥
    if is_save:
        print(f"\n7ï¸âƒ£ ëª¨ë¸ ì €ì¥...")
        save_dir = 'results/Final_Model'
        os.makedirs(save_dir, exist_ok=True)
        model_path = os.path.join(save_dir, f'Exclude_Features_selection_00_{ensemble_strategy}_model.joblib')
        joblib.dump(final_model, model_path)
        print(f"   âœ… ì €ì¥ ì™„ë£Œ: {model_path}")
    
    print(f"\n{'='*80}")
    print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print(f"{'='*80}\n")
    
    return {
        'cv_results': cv_results,
        'summary': summary,
        'final_model': final_model,
        'best_fold_model': models[np.argmax([r['f1'] for r in cv_results])]
    }


if __name__ == '__main__':
    
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    
    # ì‹¤í–‰
    results = run(
        df=df,
        is_preprocess=True,
        is_feature_engineering=False,
        cv_strategy='stratified_kfold',  # 'stratified_kfold', 'kfold', None
        tuning_strategy='optuna',  # None, 'optuna', 'grid_search', 'random_search'
        ensemble_strategy='stacking',  # 'stacking', 'voting', 'logistic'
        is_save=True
    )