# 모델 학습 결과서

## 1. 최종 모델 선정을 위한 평가 지표와 그에 대한 설명

- 모델별 성능 평가 실험 내용

## 2. 최종 선정 된 모델에 대한 설명

- **선정 모델**: <span style="color:#0066cc;">LightGBM (Gradient Boosting Decision Tree)</span>

  - 사용한 파라미터: `learning_rate=?`, `num_leaves=?`, `max_depth=?`, `feature_fraction=?`, `bagging_fraction=?`, `bagging_freq=?`
  - 학습에 활용한 피처 수: **?개** (전처리 단계에서 결측치 처리·원-핫 인코딩 후)

- **앙상블 전략** 

  - 하이퍼 파라미터 튜닝된 RandomForest와 XGBoost 모델을 기반으로 Voting과 Stacking 앙상블을 적용했습니다.  Logistic을 최종 분류기로 적용해 더 정교한 의사결정을 수행했습니다. 서로 다른 알고리즘이 학습한 패턴을 통합함으로, 단일 모델로는 포착하기 어려운 관계를 반영했습니다. 
  - 앙상블 적용 시 AUC‑ROC가 `+0.00928` 상승.

- **핵심 특징 및 해석**

  - 가장 중요한 피처(상위 5개): `총 이용 건수`, `월 평균 사용량`, `계약 기간`, `고객 연령`, `최근 결제 지연 일수`.
  - SHAP 값을 활용해 모델이 **‘고객 이탈 가능성 ↑’** 로 예측한 이유를 시각화하고, 비즈니스 팀에 인사이트 제공.

## 3. 학습 과정 기록 (문지영, 김준석, 신병탁, 이명준)

### (1) 어떤 모델들을 학습했고 그 성능은 어느 정도인지에 대한 설명

- 모델의 객관적인 정확도를 어떻게 측정하려 했는지 (CV방법)
- 어떤 모델을 사용했는지
- 앙상블은 어떤 전략으로 사용했는지

### (2) 하이퍼파라미터 튜닝 과정에 대한 설명(김준석, 신병탁)

| 용어                     | 의미                                                                           | 언제 쓰나요?                                               |
| ------------------------ | ------------------------------------------------------------------------------ | ---------------------------------------------------------- |
| Grid Search              | 미리 정의한 파라미터 조합을 모두 탐색해 가장 좋은 조합을 찾음.                 | 파라미터 개수가 적고, 전체 조합을 시도해도 비용이 낮을 때. |
| Random Search            | 파라미터 분포를 정의하고, 무작위로 n_iter 번 샘플링해 탐색.                    | 파라미터 공간이 넓고, 전체 조합을 탐색하기엔 비용이 클 때. |
| Optuna (베이지안 최적화) | 베이지안 최적화 + 트리‑파라미터‑분포를 이용해 효율적으로 최적 파라미터를 찾음. | 고차원·복잡한 파라미터 공간, 연산 비용이 큰 모델에 적합.   |

- 실제 테스트 결과
  | 모델 | Grid Search | Random Search | Optuna |
  |---|---|---|---|
  | AUC‑ROC | `0.??` | `0.??` | `0.??` |
  | Accuracy | `0.??` | `0.??` | `0.??` |

### (3) 최종 모델과 최종 평가 지표에 대해 기술

- **객관적인 정확도 측정 방법 (CV)**

  - **Stratified K‑Fold Cross‑Validation (K=5)** 을 적용해 클래스 비율(16%)을 유지하면서 5개의 폴드에서 모델을 학습·평가.
  - 각 폴드마다 **AUC‑ROC**, **F1‑Score**, **Recall**, **Precision** 등을 기록하고, 최종 성능은 평균값을 사용.
  - 두가지의 CV 방법 중에서 RMSE, MAE, MAPE를 기준으로 CV전략 선택
    - K-Fold
    - ✅ Stratify K-Fold

- **평가 지표**

  - **AUC‑ROC**: `0.??` (전체 평균)
  - **Accuracy**: `0.??`
  - 이렇게 나눈 이유?
    Accuracy는 클래스 불균형 취약점이 있어 AUC‑ROC도 같이 사용
    AUC-ROC란 False Positive Rate(FPR)과 True Positive Rate(TPR)를
