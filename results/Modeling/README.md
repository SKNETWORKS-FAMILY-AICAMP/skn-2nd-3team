# 모델 학습 결과서

## 1. 최종 모델 선정을 위한 평가 지표와 그에 대한 설명

- 모델별 성능 평가 실험 내용

## 2. 최종 선정 된 모델에 대한 설명

- **선정 모델**: <span style="color:#0066cc;">LightGBM (Gradient Boosting Decision Tree)</span>

  - 사용한 파라미터: `learning_rate=?`, `num_leaves=?`, `max_depth=?`, `feature_fraction=?`, `bagging_fraction=?`, `bagging_freq=?`
  - 학습에 활용한 피처 수: **?개** (전처리 단계에서 결측치 처리·원-핫 인코딩 후)

- **앙상블 전략** (선택 사항)

  - ?????????????????????? 를 결합해 최종 예측을 향상시켰음.
  - 앙상블 적용 시 AUC‑ROC가 `+0.???` 상승.

- **핵심 특징 및 해석**

  - 가장 중요한 피처(상위 5개): `총 이용 건수`, `월 평균 사용량`, `계약 기간`, `고객 연령`, `최근 결제 지연 일수`.
  - SHAP 값을 활용해 모델이 **‘고객 이탈 가능성 ↑’** 로 예측한 이유를 시각화하고, 비즈니스 팀에 인사이트 제공.

## 3. 학습 과정 기록 (문지영, 김준석, 신병탁, 이명준)

### (1) 어떤 모델들을 학습했고 그 성능은 어느 정도인지에 대한 설명

- 모델의 객관적인 정확도를 어떻게 측정하려 했는지 (CV방법)
- 어떤 모델을 사용했는지
- 앙상블은 어떤 전략으로 사용했는지

### (2) 하이퍼파라미터 튜닝 과정에 대한 설명(김준석, 신병탁)

### (3) 최종 모델과 최종 평가 지표에 대해 기술

- **객관적인 정확도 측정 방법 (CV)**

  - **Stratified K‑Fold Cross‑Validation (K=5)** 을 적용해 클래스 비율(16%)을 유지하면서 5개의 폴드에서 모델을 학습·평가.
  - 각 폴드마다 **AUC‑ROC**, **F1‑Score**, **Recall**, **Precision** 등을 기록하고, 최종 성능은 평균값을 사용.
  - 두가지의 CV 방법 중에서 RMSE, MAE, MAPE를 기준으로 CV전략 선택
    - K-Fold
    - ✅ Stratify K-Fold

- **평가 지표**

  - **AUC‑ROC**: `0.??` (전체 평균)
  - **F1‑Score**: `0.??` (양성 클래스 기준)
  - **Recall**: `0.??` (양성 클래스 재현율)
  - **Precision**: `0.??`
