"""
n_trialsì— ë”°ë¥¸ ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸

ensemble_strategy = ['voting', 'stacking'] ë‘ ê°€ì§€ ì•™ìƒë¸” ëª¨ë¸ì— ëŒ€í•´
n_trialsë¥¼ 30ë¶€í„° 450ê¹Œì§€ 30ì”© ì¦ê°€ì‹œí‚¤ë©´ì„œ íŠœë‹í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import os
from typing import Dict, List

try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False
    def tqdm(iterable, desc=None):
        return iterable

from src.preprocessing import load_data, preprocess_pipeline, feature_engineering_pipeline, drop_column
from src.cv import stratified_kfold_split
from src.ensemble import train_stacking_ensemble, train_voting_ensemble, evaluate_model

# í™˜ê²½ ë³€ìˆ˜ IBSQR_USE_GPU=0 ë¡œ ì„¤ì •í•˜ë©´ ê°•ì œë¡œ CPU ì‚¬ìš©
# LightGBMì€ í•­ìƒ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ ê¸°ë³¸ê°’ì„ Falseë¡œ ì„¤ì •
USE_GPU = os.environ.get("IBSQR_USE_GPU", "0").lower() in {"1", "true", "yes"}


def run_single_experiment(
    df: pd.DataFrame,
    ensemble_strategy: str,
    n_trials: int,
    cv_strategy: str = 'stratified_kfold',
    target_col: str = "Attrition_Binary",
    use_gpu: bool = False
) -> Dict[str, float]:
    """
    ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰: ì£¼ì–´ì§„ ensemble_strategyì™€ n_trialsë¡œ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    
    Args:
        df: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        ensemble_strategy: 'voting' ë˜ëŠ” 'stacking'
        n_trials: Optuna íŠœë‹ ì‹œë„ íšŸìˆ˜
        cv_strategy: CV ì „ëµ
        target_col: íƒ€ê²Ÿ ì»¬ëŸ¼ëª…
        use_gpu: XGBoost/LightGBM í•™ìŠµ ì‹œ GPU ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        Dict[str, float]: í‰ê°€ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    
    # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    features = df.drop(columns=[target_col]).columns.tolist()
    X_full = df[features]
    y_full = df[target_col]
    
    # ì „ì²´ ë°ì´í„°ë¡œ íŠœë‹í•˜ì—¬ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°
    if ensemble_strategy == 'stacking':
        tuned_model, tuned_params = train_stacking_ensemble(
            X_full, y_full,
            cv_strategy=cv_strategy,
            tuning_strategy='optuna',
            n_trials=n_trials,
            return_params=True,
            use_gpu=use_gpu
        )
    elif ensemble_strategy == 'voting':
        tuned_model, tuned_params = train_voting_ensemble(
            X_full, y_full,
            cv_strategy=cv_strategy,
            tuning_strategy='optuna',
            n_trials=n_trials,
            return_params=True,
            use_gpu=use_gpu
        )
    else:
        raise ValueError(f"Unknown ensemble_strategy: {ensemble_strategy}")
    
    # CV ì„¤ì •
    if cv_strategy == 'stratified_kfold':
        folds = stratified_kfold_split(df, target_col=target_col, n_splits=5, shuffle=True, random_state=42)
    else:
        from sklearn.model_selection import train_test_split
        train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[target_col], random_state=42)
        folds = [(train_df.index.tolist(), test_df.index.tolist())]
    
    # ê° í´ë“œì—ì„œ í‰ê°€ (íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
    cv_results = []
    
    for train_idx, val_idx in folds:
        # ë°ì´í„° ë¶„í• 
        X_train = df.loc[train_idx, features]
        y_train = df.loc[train_idx, target_col]
        X_val = df.loc[val_idx, features]
        y_val = df.loc[val_idx, target_col]
        
        # ëª¨ë¸ í•™ìŠµ (íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        if ensemble_strategy == 'stacking':
            model = train_stacking_ensemble(
                X_train, y_train,
                cv_strategy=cv_strategy,
                tuning_strategy=None,
                best_params=tuned_params,
                use_gpu=use_gpu
            )
        elif ensemble_strategy == 'voting':
            model = train_voting_ensemble(
                X_train, y_train,
                cv_strategy=cv_strategy,
                tuning_strategy=None,
                best_params=tuned_params,
                use_gpu=use_gpu
            )
        
        # í‰ê°€ (ì¶œë ¥ ì—†ì´)
        metrics = evaluate_model(
            model, X_val, y_val,
            print_report=False
        )
        
        cv_results.append(metrics)
    
    # CV ê²°ê³¼ í‰ê·  ê³„ì‚°
    summary = {}
    for metric in cv_results[0].keys():
        values = [r[metric] for r in cv_results]
        summary[metric] = np.mean(values)
    
    return summary


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print(f"\n{'='*80}")
    print("ğŸ”¬ n_trialsì— ë”°ë¥¸ ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜")
    print(f"{'='*80}\n")
    
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    print("1ï¸âƒ£ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬...")
    df = load_data()
    df = preprocess_pipeline(df)
    df = feature_engineering_pipeline(df)
    print(f"   âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {df.shape}\n")
    
    # ì‹¤í—˜ ì„¤ì •
    ensemble_strategies = ['voting', 'stacking']
    n_trials_list = list(range(30, 451, 30))  # 30, 60, 90, ..., 450
    
    print(f"2ï¸âƒ£ ì‹¤í—˜ ì„¤ì •:")
    print(f"   - ì•™ìƒë¸” ì „ëµ: {ensemble_strategies}")
    print(f"   - n_trials: {n_trials_list}")
    print(f"   - ì—°ì‚° ì¥ì¹˜: {'GPU' if USE_GPU else 'CPU'}")
    print(f"   - ì´ ì‹¤í—˜ ìˆ˜: {len(ensemble_strategies) * len(n_trials_list)}ê°œ\n")
    
    # ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
    save_dir = 'results/parameter_tuning'
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, 'n_trials_comparison.csv')
    
    # ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
    if os.path.exists(save_path):
        print(f"ğŸ“‚ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {save_path}")
        existing_results = pd.read_csv(save_path, encoding='utf-8-sig')
        print(f"   - ê¸°ì¡´ ì‹¤í—˜ ìˆ˜: {len(existing_results)}ê°œ")
        print(f"   - ë§ˆì§€ë§‰ ì‹¤í—˜: {existing_results.iloc[-1]['ensemble_strategy']} - n_trials={existing_results.iloc[-1]['n_trials']}\n")
    else:
        print(f"ğŸ“‚ ìƒˆë¡œìš´ ì‹¤í—˜ ì‹œì‘\n")
        existing_results = pd.DataFrame()
    
    # ê° ì¡°í•©ì— ëŒ€í•´ ì‹¤í—˜ ì‹¤í–‰
    total_experiments = len(ensemble_strategies) * len(n_trials_list)
    experiment_num = 0
    
    for ensemble_strategy in ensemble_strategies:
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ì•™ìƒë¸” ì „ëµ: {ensemble_strategy.upper()}")
        print(f"{'='*80}\n")
        
        iterator = tqdm(n_trials_list, desc=f"{ensemble_strategy} ì§„í–‰ ì¤‘") if HAS_TQDM else n_trials_list
        for n_trials in iterator:
            experiment_num += 1
            
            # ì´ë¯¸ ì‹¤í—˜ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if not existing_results.empty:
                already_done = existing_results[
                    (existing_results['ensemble_strategy'] == ensemble_strategy) & 
                    (existing_results['n_trials'] == n_trials)
                ]
                if not already_done.empty:
                    print(f"\n[{experiment_num}/{total_experiments}] {ensemble_strategy} - n_trials={n_trials}")
                    print(f"   â­ï¸  ì´ë¯¸ ì™„ë£Œëœ ì‹¤í—˜ - ê±´ë„ˆëœ€")
                    continue
            
            print(f"\n[{experiment_num}/{total_experiments}] {ensemble_strategy} - n_trials={n_trials}")
            
            try:
                # ì‹¤í—˜ ì‹¤í–‰
                metrics = run_single_experiment(
                    df=df,
                    ensemble_strategy=ensemble_strategy,
                    n_trials=n_trials,
                    cv_strategy='stratified_kfold',
                    use_gpu=USE_GPU
                )
                
                # ê²°ê³¼ ì €ì¥
                result_row = {
                    'ensemble_strategy': ensemble_strategy,
                    'n_trials': n_trials,
                    'accuracy': metrics['accuracy'],
                    'roc_auc': metrics['roc_auc'],
                    'pr_auc': metrics['pr_auc'],
                    'f1': metrics['f1'],
                    'recall': metrics['recall'],
                    'precision': metrics['precision'],
                    'device': 'gpu' if USE_GPU else 'cpu'
                }
                
                print(f"   âœ… ì™„ë£Œ - Accuracy: {metrics['accuracy']:.4f}, F1: {metrics['f1']:.4f}, ROC-AUC: {metrics['roc_auc']:.4f}")
                
            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê²°ê³¼ì— ì¶”ê°€ (NaN ê°’ìœ¼ë¡œ)
                result_row = {
                    'ensemble_strategy': ensemble_strategy,
                    'n_trials': n_trials,
                    'accuracy': np.nan,
                    'roc_auc': np.nan,
                    'pr_auc': np.nan,
                    'f1': np.nan,
                    'recall': np.nan,
                    'precision': np.nan,
                    'device': 'gpu' if USE_GPU else 'cpu'
                }
            
            # ê¸°ì¡´ ê²°ê³¼ì— ìƒˆ ê²°ê³¼ ì¶”ê°€í•˜ì—¬ ì¦‰ì‹œ ì €ì¥
            new_result_df = pd.DataFrame([result_row])
            if existing_results.empty:
                existing_results = new_result_df
            else:
                existing_results = pd.concat([existing_results, new_result_df], ignore_index=True)
            
            # CSV íŒŒì¼ì— ì €ì¥
            existing_results.to_csv(save_path, index=False, encoding='utf-8-sig')
            print(f"   ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}")
    
    print(f"\n{'='*80}")
    print("âœ… ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
    print(f"{'='*80}")
    print(f"\nğŸ“ ìµœì¢… ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {save_path}")
    print(f"\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    print(existing_results.groupby('ensemble_strategy').agg({
        'accuracy': ['mean', 'std'],
        'f1': ['mean', 'std'],
        'roc_auc': ['mean', 'std']
    }))
    print(f"\n")


if __name__ == '__main__':
    main()

