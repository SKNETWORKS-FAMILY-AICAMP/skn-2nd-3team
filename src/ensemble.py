"""
ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
- Voting Classifier (íˆ¬í‘œ ê¸°ë°˜ ì•™ìƒë¸”)
- Stacking Classifier (ìŠ¤íƒœí‚¹ ì•™ìƒë¸”)
- ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
"""

from typing import Tuple, List, Optional, Dict, Any, Union
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, roc_auc_score, classification_report, 
    f1_score, recall_score, precision_score, average_precision_score
)
from sklearn.model_selection import StratifiedKFold, KFold
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier


####################################
# ğŸ”§ CV í—¬í¼ í•¨ìˆ˜
####################################
def _get_cv_splitter(
    cv_method: Optional[str] = None,
    n_splits: int = 5,
    shuffle: bool = True,
    random_state: int = 42
) -> Union[int, Any]:
    """
    CV ì „ëµì„ ì„ íƒí•˜ì—¬ ì ì ˆí•œ CV splitterë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ğŸ’¡ cv.pyì˜ í•¨ìˆ˜ë“¤ì„ sklearn í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        cv_method: CV ë°©ë²• ì„ íƒ
            - None or 'default': ê¸°ë³¸ int ë°˜í™˜ (sklearn ìë™ ì²˜ë¦¬)
            - 'stratified_kfold': StratifiedKFold (ë¶ˆê· í˜• ë°ì´í„° ì¶”ì²œ!)
            - 'kfold': KFold
        n_splits: í´ë“œ ìˆ˜
        shuffle: ì„ê¸° ì—¬ë¶€
        random_state: ëœë¤ ì‹œë“œ
    
    Returns:
        sklearn CV splitter ë˜ëŠ” int
        
    ì˜ˆì‹œ:
        >>> cv = _get_cv_splitter('stratified_kfold', n_splits=5)
        >>> # StratifiedKFold(n_splits=5, shuffle=True, random_state=42) ë°˜í™˜
    """
    
    if cv_method is None or cv_method == 'default':
        # sklearnì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ (classificationì´ë©´ StratifiedKFold ì‚¬ìš©)
        return n_splits
    
    elif cv_method == 'stratified_kfold':
        # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€ (ë¶ˆê· í˜• ë°ì´í„°ì— ì í•©)
        return StratifiedKFold(
            n_splits=n_splits,
            shuffle=shuffle,
            random_state=random_state
        )
    
    elif cv_method == 'kfold':
        # ì¼ë°˜ KFold
        return KFold(
            n_splits=n_splits,
            shuffle=shuffle,
            random_state=random_state
        )
    
    else:
        raise ValueError(
            f"Unknown cv_method: {cv_method}\n"
            f"Available options: None, 'default', 'stratified_kfold', 'kfold'"
        )

####################################
# ğŸ“Œ ê³µí†µ í•¨ìˆ˜: ê¸°ë³¸ ëª¨ë¸ ìƒì„± ë° íŠœë‹
####################################
def _create_base_models(
    scale_pos_weight: float,
    X_train: Optional[pd.DataFrame] = None,
    y_train: Optional[pd.Series] = None,
    tuning_strategy: Optional[str] = None,
    cv: int = 5,
    n_trials: int = 50
) -> List[Tuple[str, Any]]:
    """
    ì•™ìƒë¸”ì— ì‚¬ìš©í•  ê¸°ë³¸ ëª¨ë¸ë“¤(Random Forest, XGBoost, LightGBM)ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì„ íƒì ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ğŸ’¡ ì„¤ê³„ ì² í•™:
    1. ê¸°ë³¸ ëª¨ë“œ (tuning_strategy=None): ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
    2. íŠœë‹ ëª¨ë“œ (tuning_strategy='optuna' ë“±): ì„±ëŠ¥ ìµœì í™”
    
    Args:
        scale_pos_weight (float): í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ê°€ì¤‘ì¹˜
        X_train (Optional[pd.DataFrame]): íŠœë‹ ì‹œ í•„ìš”í•œ í›ˆë ¨ ë°ì´í„° (íŠœë‹ ì•ˆí•˜ë©´ None ê°€ëŠ¥)
        y_train (Optional[pd.Series]): íŠœë‹ ì‹œ í•„ìš”í•œ íƒ€ê²Ÿ ë°ì´í„° (íŠœë‹ ì•ˆí•˜ë©´ None ê°€ëŠ¥)
        tuning_strategy (Optional[str]): íŠœë‹ ë°©ë²•
            - None: ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš© (ë¹ ë¦„)
            - 'grid_search': ê²©ì íƒìƒ‰ (ì „ìˆ˜ ì¡°ì‚¬, ëŠë¦¼)
            - 'random_search': ëœë¤ íƒìƒ‰ (ì¤‘ê°„)
            - 'optuna': Optuna ë² ì´ì§€ì•ˆ ìµœì í™” (ì¶”ì²œ!)
        cv (int): êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜
        n_trials (int): Optuna/RandomSearch ì‹œë„ íšŸìˆ˜
    
    Returns:
        List[Tuple[str, model]]: (ëª¨ë¸ì´ë¦„, ëª¨ë¸ê°ì²´) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        
    ì˜ˆì‹œ:
        # ê¸°ë³¸ ëª¨ë“œ (ë¹ ë¦„)
        >>> models = _create_base_models(scale_pos_weight=3.0)
        
        # íŠœë‹ ëª¨ë“œ (ëŠë¦¬ì§€ë§Œ ì„±ëŠ¥ ì¢‹ìŒ)
        >>> models = _create_base_models(
        ...     scale_pos_weight=3.0,
        ...     X_train=X_train,
        ...     y_train=y_train,
        ...     tuning_strategy='optuna',
        ...     n_trials=50
        ... )
    """
    
    # ğŸ” íŠœë‹ ì—¬ë¶€ í™•ì¸
    if tuning_strategy is not None:
        if X_train is None or y_train is None:
            raise ValueError(
                "âŒ íŠœë‹ì„ í•˜ë ¤ë©´ X_trainê³¼ y_trainì´ í•„ìš”í•©ë‹ˆë‹¤!\n"
                "   _create_base_models(..., X_train=X, y_train=y, tuning_strategy='optuna')"
            )
        print(f"\nğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ëª¨ë“œ: {tuning_strategy}")
        print(f"   ë°ì´í„° í¬ê¸°: {X_train.shape}, CV={cv}, Trials={n_trials}")
        return _tune_base_models(
            X_train=X_train,
            y_train=y_train,
            scale_pos_weight=scale_pos_weight,
            tuning_strategy=tuning_strategy,
            cv=cv,
            n_trials=n_trials
        )
    
    # ğŸ“¦ ê¸°ë³¸ ëª¨ë“œ: ë¯¸ë¦¬ ì •ì˜ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©
    print("\nâš¡ ê¸°ë³¸ íŒŒë¼ë¯¸í„° ëª¨ë“œ (íŠœë‹ ì—†ìŒ)")
    
    # ğŸŒ² Random Forest ì„¤ì •
    rf_model = RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        min_samples_split=5,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )

    # ğŸš€ XGBoost ì„¤ì •
    xgb_model = XGBClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=5,
        subsample=0.9,
        colsample_bytree=0.9,
        scale_pos_weight=scale_pos_weight,
        eval_metric="logloss",
        random_state=42,
        n_jobs=-1,
        verbosity=0
    )

    # ğŸ’¡ LightGBM ì„¤ì •
    lgbm_model = LGBMClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=5,
        subsample=0.9,
        colsample_bytree=0.9,
        scale_pos_weight=scale_pos_weight,
        random_state=42,
        n_jobs=-1,
        verbosity=-1
    )

    return [
        ('rf', rf_model),
        ('xgb', xgb_model),
        ('lgbm', lgbm_model)
    ]


####################################
# ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•¨ìˆ˜
####################################
def _tune_base_models(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    scale_pos_weight: float,
    tuning_strategy: str = 'optuna',
    cv: int = 5,
    n_trials: int = 50
) -> List[Tuple[str, Any]]:
    """
    ê° ê¸°ë³¸ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•©ë‹ˆë‹¤.
    
    ğŸ’¡ íŠœë‹ ì „ëµ ë¹„êµ:
    - grid_search: ëª¨ë“  ì¡°í•© ì‹œë„ (ì™„ë²½í•˜ì§€ë§Œ ë§¤ìš° ëŠë¦¼)
    - random_search: ëœë¤ ìƒ˜í”Œë§ (ë¹ ë¥´ê³  ê´œì°®ìŒ)
    - optuna: ë² ì´ì§€ì•ˆ ìµœì í™” (ë˜‘ë˜‘í•˜ê³  íš¨ìœ¨ì , ì¶”ì²œ!)
    
    ğŸ’¡ ê° ëª¨ë¸ë³„ ì¤‘ìš” íŒŒë¼ë¯¸í„°:
    - Random Forest: n_estimators, max_depth, min_samples_split
    - XGBoost: learning_rate, max_depth, subsample, colsample_bytree
    - LightGBM: learning_rate, num_leaves, max_depth
    """
    from src.tuner import grid_search_tuner, random_search_tuner, optuna_tuner
    import optuna
    
    tuned_models = []
    
    # ğŸŒ² Random Forest íŠœë‹
    print("\nğŸŒ² Random Forest íŠœë‹ ì¤‘...")
    if tuning_strategy == 'optuna':
        def rf_factory(trial: optuna.Trial):
            return RandomForestClassifier(
                n_estimators=trial.suggest_int('n_estimators', 100, 500),
                max_depth=trial.suggest_int('max_depth', 5, 20),
                min_samples_split=trial.suggest_int('min_samples_split', 2, 10),
                class_weight='balanced',
                random_state=42,
                n_jobs=-1
            )
        rf_best, rf_params, rf_score = optuna_tuner(
            rf_factory, X_train, y_train, 
            cv=cv, n_trials=n_trials, scoring='recall'
        )
    elif tuning_strategy == 'grid_search':
        from src.tuner import grid_search_tuner
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [5, 10, 15],
            'min_samples_split': [2, 5, 10]
        }
        rf_best, rf_params, rf_score = grid_search_tuner(
            RandomForestClassifier(class_weight='balanced', random_state=42),
            param_grid, X_train, y_train, cv=cv, scoring='recall'
        )
    elif tuning_strategy == 'random_search':
        from src.tuner import random_search_tuner
        from scipy.stats import randint
        param_dist = {
            'n_estimators': randint(100, 500),
            'max_depth': randint(5, 20),
            'min_samples_split': randint(2, 10)
        }
        rf_best, rf_params, rf_score = random_search_tuner(
            RandomForestClassifier(class_weight='balanced', random_state=42),
            param_dist, X_train, y_train, 
            cv=cv, n_iter=n_trials, scoring='recall'
        )
    
    print(f"   âœ… ìµœì  íŒŒë¼ë¯¸í„°: {rf_params}")
    print(f"   âœ… CV ì ìˆ˜: {rf_score:.4f}")
    tuned_models.append(('rf', rf_best))
    
    # ğŸš€ XGBoost íŠœë‹
    print("\nğŸš€ XGBoost íŠœë‹ ì¤‘...")
    if tuning_strategy == 'optuna':
        def xgb_factory(trial: optuna.Trial):
            return XGBClassifier(
                n_estimators=trial.suggest_int('n_estimators', 100, 500),
                learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                max_depth=trial.suggest_int('max_depth', 3, 10),
                subsample=trial.suggest_float('subsample', 0.6, 1.0),
                colsample_bytree=trial.suggest_float('colsample_bytree', 0.6, 1.0),
                scale_pos_weight=scale_pos_weight,
                eval_metric="logloss",
                random_state=42,
                n_jobs=-1,
                verbosity=0
            )
        xgb_best, xgb_params, xgb_score = optuna_tuner(
            xgb_factory, X_train, y_train,
            cv=cv, n_trials=n_trials, scoring='recall'
        )
    elif tuning_strategy == 'grid_search':
        param_grid = {
            'n_estimators': [100, 200, 300],
            'learning_rate': [0.01, 0.05, 0.1],
            'max_depth': [3, 5, 7]
        }
        xgb_best, xgb_params, xgb_score = grid_search_tuner(
            XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42, verbosity=0),
            param_grid, X_train, y_train, cv=cv, scoring='recall'
        )
    elif tuning_strategy == 'random_search':
        from scipy.stats import uniform, randint
        param_dist = {
            'n_estimators': randint(100, 500),
            'learning_rate': uniform(0.01, 0.29),
            'max_depth': randint(3, 10)
        }
        xgb_best, xgb_params, xgb_score = random_search_tuner(
            XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42, verbosity=0),
            param_dist, X_train, y_train,
            cv=cv, n_iter=n_trials, scoring='recall'
        )
    
    print(f"   âœ… ìµœì  íŒŒë¼ë¯¸í„°: {xgb_params}")
    print(f"   âœ… CV ì ìˆ˜: {xgb_score:.4f}")
    tuned_models.append(('xgb', xgb_best))
    
    # ğŸ’¡ LightGBM íŠœë‹
    print("\nğŸ’¡ LightGBM íŠœë‹ ì¤‘...")
    if tuning_strategy == 'optuna':
        def lgbm_factory(trial: optuna.Trial):
            return LGBMClassifier(
                n_estimators=trial.suggest_int('n_estimators', 100, 500),
                learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                num_leaves=trial.suggest_int('num_leaves', 20, 100),
                max_depth=trial.suggest_int('max_depth', 3, 10),
                subsample=trial.suggest_float('subsample', 0.6, 1.0),
                colsample_bytree=trial.suggest_float('colsample_bytree', 0.6, 1.0),
                scale_pos_weight=scale_pos_weight,
                random_state=42,
                n_jobs=-1,
                verbosity=-1
            )
        lgbm_best, lgbm_params, lgbm_score = optuna_tuner(
            lgbm_factory, X_train, y_train,
            cv=cv, n_trials=n_trials, scoring='recall'
        )
    elif tuning_strategy == 'grid_search':
        param_grid = {
            'n_estimators': [100, 200, 300],
            'learning_rate': [0.01, 0.05, 0.1],
            'num_leaves': [31, 50, 70],
            'max_depth': [3, 5, 7]
        }
        lgbm_best, lgbm_params, lgbm_score = grid_search_tuner(
            LGBMClassifier(scale_pos_weight=scale_pos_weight, random_state=42, verbosity=-1),
            param_grid, X_train, y_train, cv=cv, scoring='recall'
        )
    else:  # random_search
        from scipy.stats import uniform, randint
        param_dist = {
            'n_estimators': randint(100, 500),
            'learning_rate': uniform(0.01, 0.29),
            'num_leaves': randint(20, 100),
            'max_depth': randint(3, 10)
        }
        lgbm_best, lgbm_params, lgbm_score = random_search_tuner(
            LGBMClassifier(scale_pos_weight=scale_pos_weight, random_state=42, verbosity=-1),
            param_dist, X_train, y_train,
            cv=cv, n_iter=n_trials, scoring='recall'
        )
    
    print(f"   âœ… ìµœì  íŒŒë¼ë¯¸í„°: {lgbm_params}")
    print(f"   âœ… CV ì ìˆ˜: {lgbm_score:.4f}")
    tuned_models.append(('lgbm', lgbm_best))
    
    print("\nğŸ‰ ëª¨ë“  ëª¨ë¸ íŠœë‹ ì™„ë£Œ!\n")
    
    return tuned_models


####################################
# ğŸ—³ï¸ Voting Ensemble
####################################
def train_voting_ensemble(
    X_train: pd.DataFrame, 
    y_train: pd.Series, 
    cv_strategy: Optional[str] = 'stratified_kfold',  # CV ì „ëµ
    tuning_strategy: Optional[str] = None,  # íŠœë‹ ì „ëµ
    rf_weight: int = 1,
    xgb_weight: int = 2,
    lgbm_weight: int = 2,
    voting: str = 'soft',
    n_splits: int = 5,
    n_trials: int = 50
) -> VotingClassifier:
    """
    Voting Classifier í•™ìŠµ (íˆ¬í‘œ ê¸°ë°˜ ì•™ìƒë¸”)
    
    Args:
        X_train, y_train: í›ˆë ¨ ë°ì´í„°
        cv_strategy: CV ì „ëµ ('stratified_kfold', 'kfold', None)
        tuning_strategy: íŠœë‹ ì „ëµ (None, 'optuna', 'grid_search', 'random_search')
        rf_weight, xgb_weight, lgbm_weight: ê° ëª¨ë¸ì˜ íˆ¬í‘œ ê°€ì¤‘ì¹˜
        voting: 'soft' (í™•ë¥  í‰ê· ) or 'hard' (ë‹¤ìˆ˜ê²°)
        n_splits: CV í´ë“œ ìˆ˜
        n_trials: íŠœë‹ ì‹œë„ íšŸìˆ˜
    
    Returns:
        VotingClassifier: í•™ìŠµëœ ëª¨ë¸
    """
    
    # í´ë˜ìŠ¤ ë¶ˆê· í˜• ê³„ì‚°
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

    # CV splitter ìƒì„±
    cv_splitter = _get_cv_splitter(cv_strategy, n_splits)
    
    # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
    estimators = _create_base_models(
        scale_pos_weight=scale_pos_weight,
        X_train=X_train,
        y_train=y_train,
        tuning_strategy=tuning_strategy,
        cv=cv_splitter,
        n_trials=n_trials
    )

    # Voting ì•™ìƒë¸” ìƒì„± ë° í•™ìŠµ
    voting_model = VotingClassifier(
        estimators=estimators,
        voting=voting,
        weights=[rf_weight, xgb_weight, lgbm_weight],
        n_jobs=-1
    )
    voting_model.fit(X_train, y_train)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    
    return voting_model


####################################
# ğŸ“š Stacking Ensemble
####################################
def train_stacking_ensemble(
    X_train: pd.DataFrame, 
    y_train: pd.Series, 
    cv_strategy: Optional[str] = 'stratified_kfold',  # CV ì „ëµ
    tuning_strategy: Optional[str] = None,  # íŠœë‹ ì „ëµ
    final_estimator: Optional[Any] = None,
    n_splits: int = 5,
    n_trials: int = 50
) -> StackingClassifier:
    """
    Stacking Classifier í•™ìŠµ (ìŠ¤íƒœí‚¹ ì•™ìƒë¸”)
    
    ğŸ’¡ Stackingì€ ì™œ CVê°€ í•„ìˆ˜?
    - ë² ì´ìŠ¤ ëª¨ë¸ì´ "ë³¸ ì  ì—†ëŠ”" ë°ì´í„°ë¡œ ì˜ˆì¸¡ê°’ ìƒì„±
    - ë©”íƒ€ ëª¨ë¸ì´ ì´ ì˜ˆì¸¡ê°’ìœ¼ë¡œ í•™ìŠµ â†’ ê³¼ì í•© ë°©ì§€!
    
    Args:
        X_train, y_train: í›ˆë ¨ ë°ì´í„°
        cv_strategy: CV ì „ëµ ('stratified_kfold', 'kfold', None)
        tuning_strategy: íŠœë‹ ì „ëµ (None, 'optuna', 'grid_search', 'random_search')
        final_estimator: ë©”íƒ€ ëª¨ë¸ (Noneì´ë©´ LogisticRegression)
        n_splits: CV í´ë“œ ìˆ˜
        n_trials: íŠœë‹ ì‹œë„ íšŸìˆ˜
    
    Returns:
        StackingClassifier: í•™ìŠµëœ ëª¨ë¸
    """
    
    # í´ë˜ìŠ¤ ë¶ˆê· í˜• ê³„ì‚°
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

    # CV splitter ìƒì„±
    cv_splitter = _get_cv_splitter(cv_strategy, n_splits)
    
    # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
    estimators = _create_base_models(
        scale_pos_weight=scale_pos_weight,
        X_train=X_train,
        y_train=y_train,
        tuning_strategy=tuning_strategy,
        cv=cv_splitter,
        n_trials=n_trials
    )

    # ë©”íƒ€ ëª¨ë¸ ì„¤ì •
    if final_estimator is None:
        final_estimator = LogisticRegression(
            max_iter=1000,
            random_state=42,
            class_weight='balanced'
        )

    # Stacking ì•™ìƒë¸” ìƒì„± ë° í•™ìŠµ
    stacking_model = StackingClassifier(
        estimators=estimators,
        final_estimator=final_estimator,
        stack_method='predict_proba',
        cv=cv_splitter,  # ğŸ‘ˆ ê³¼ì í•© ë°©ì§€ìš© CV (í•„ìˆ˜!)
        n_jobs=-1
    )
    
    stacking_model.fit(X_train, y_train)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    
    return stacking_model


####################################
# ğŸ“ˆ ë‹¨ì¼ ëª¨ë¸: Logistic Regression
####################################
def train_logistic_regression(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    class_weight: str = 'balanced'
) -> LogisticRegression:
    """
    ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ
    
    ğŸ’¡ ê°œì„ : max_iterë¥¼ 5000ìœ¼ë¡œ ì¦ê°€í•˜ì—¬ ìˆ˜ë ´ ê²½ê³  ë°©ì§€
    """
    model = LogisticRegression(
        max_iter=5000,  # ğŸ‘ˆ ConvergenceWarning ë°©ì§€
        random_state=42,
        class_weight=class_weight
    )
    model.fit(X_train, y_train)
    return model


####################################
# ğŸ“Š ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
####################################
def evaluate_model(
    model: Any,
    X_test: pd.DataFrame,
    y_test: pd.Series,
    fold_num: Optional[int] = None,
    n_splits: Optional[int] = None,
    print_report: bool = True
) -> Dict[str, float]:
    """
    ëª¨ë¸ì„ í‰ê°€í•˜ê³  ì§€í‘œë¥¼ ì¶œë ¥ ë° ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ğŸ’¡ ê°œì„  ì‚¬í•­:
    1. í‰ê°€ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜ â†’ ì €ì¥/ë¹„êµ ê°€ëŠ¥
    2. print_report ì˜µì…˜ìœ¼ë¡œ ì¶œë ¥ ì œì–´
    3. predict_proba ì§€ì› ì—¬ë¶€ í™•ì¸ (ì—ëŸ¬ ë°©ì§€)
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        X_test: í…ŒìŠ¤íŠ¸ ë°ì´í„°
        y_test: í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ
        fold_num: í˜„ì¬ í´ë“œ ë²ˆí˜¸ (êµì°¨ê²€ì¦ ì‹œ)
        n_splits: ì „ì²´ í´ë“œ ìˆ˜ (êµì°¨ê²€ì¦ ì‹œ)
        print_report: ê²°ê³¼ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        Dict[str, float]: í‰ê°€ ì§€í‘œë“¤
        {
            'accuracy': ì •í™•ë„,
            'roc_auc': ROC-AUC ì ìˆ˜,
            'f1': F1 ì ìˆ˜,
            'recall': ì¬í˜„ìœ¨,
            'precision': ì •ë°€ë„
        }
        
    ì˜ˆì‹œ:
        >>> metrics = evaluate_model(model, X_test, y_test)
        >>> print(f"F1 Score: {metrics['f1']:.4f}")
    """
    
    # ì˜ˆì¸¡
    y_pred = model.predict(X_test)
    
    # ROC-AUCì™€ PR-AUCëŠ” predict_probaë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ ê³„ì‚° ê°€ëŠ¥
    roc_auc = None
    pr_auc = None
    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X_test)[:, 1]
        roc_auc = roc_auc_score(y_test, y_proba)
        pr_auc = average_precision_score(y_test, y_proba)  # PR-AUC ê³„ì‚°
    
    # ê°ì¢… ì§€í‘œ ê³„ì‚°
    metrics = {
        'accuracy': accuracy_score(y_test, y_pred),
        'roc_auc': roc_auc if roc_auc is not None else 0.0,
        'pr_auc': pr_auc if pr_auc is not None else 0.0,  # PR-AUC ì¶”ê°€
        'f1': f1_score(y_test, y_pred),
        'recall': recall_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred)
    }
    
    # ì¶œë ¥ (í•„ìš”í•œ ê²½ìš°ì—ë§Œ)
    if print_report:
        if fold_num is not None and n_splits is not None:
            print(f"\n{'='*60}")
            print(f"  Fold {fold_num}/{n_splits} í‰ê°€ ê²°ê³¼")
            print(f"{'='*60}")
        
        print(f"ğŸ“Š ì •í™•ë„ (Accuracy):  {metrics['accuracy']:.4f}")
        if roc_auc is not None:
            print(f"ğŸ“Š ROC-AUC:            {metrics['roc_auc']:.4f}")
        if pr_auc is not None:
            print(f"ğŸ“Š PR-AUC:             {metrics['pr_auc']:.4f}")
        print(f"ğŸ“Š F1 Score:           {metrics['f1']:.4f}")
        print(f"ğŸ“Š ì¬í˜„ìœ¨ (Recall):     {metrics['recall']:.4f}")
        print(f"ğŸ“Š ì •ë°€ë„ (Precision):  {metrics['precision']:.4f}")
        print("\nğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
        print(classification_report(y_test, y_pred))
    
    return metrics

