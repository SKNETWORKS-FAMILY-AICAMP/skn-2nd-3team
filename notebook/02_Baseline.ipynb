{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e2f38e",
   "metadata": {},
   "source": [
    "# 신용카드 고객 이탈 예측 - 베이스라인 모델\n",
    "\n",
    "이 노트북은 BankChurners.csv 데이터를 활용하여 간단한 이탈 예측(Churn Prediction) 베이스라인 모델을 구축합니다.\n",
    "\n",
    "## 목차\n",
    "1. 필요한 라이브러리 임포트\n",
    "2. 데이터 불러오기 및 확인\n",
    "3. 데이터 전처리\n",
    "4. 학습/테스트 데이터 분리\n",
    "5. 베이스라인 모델 학습\n",
    "6. 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ddb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8da76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10127, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.99991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.99994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.99987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0  768805383  Existing Customer            45      M                3   \n",
       "1  818770008  Existing Customer            49      F                5   \n",
       "2  713982108  Existing Customer            51      M                3   \n",
       "3  769911858  Existing Customer            40      F                4   \n",
       "4  709106358  Existing Customer            40      M                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0     High School        Married     $60K - $80K          Blue   \n",
       "1        Graduate         Single  Less than $40K          Blue   \n",
       "2        Graduate        Married    $80K - $120K          Blue   \n",
       "3     High School        Unknown  Less than $40K          Blue   \n",
       "4      Uneducated        Married     $60K - $80K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "0              39  ...       12691.0                  777          11914.0   \n",
       "1              44  ...        8256.0                  864           7392.0   \n",
       "2              36  ...        3418.0                    0           3418.0   \n",
       "3              34  ...        3313.0                 2517            796.0   \n",
       "4              21  ...        4716.0                    0           4716.0   \n",
       "\n",
       "   Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0                 1.335             1144              42                1.625   \n",
       "1                 1.541             1291              33                3.714   \n",
       "2                 2.594             1887              20                2.333   \n",
       "3                 1.405             1171              20                2.333   \n",
       "4                 2.175              816              28                2.500   \n",
       "\n",
       "   Avg_Utilization_Ratio  \\\n",
       "0                  0.061   \n",
       "1                  0.105   \n",
       "2                  0.000   \n",
       "3                  0.760   \n",
       "4                  0.000   \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                           0.000093                                                                                    \n",
       "1                                           0.000057                                                                                    \n",
       "2                                           0.000021                                                                                    \n",
       "3                                           0.000134                                                                                    \n",
       "4                                           0.000022                                                                                    \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                            0.99991                                                                                   \n",
       "1                                            0.99994                                                                                   \n",
       "2                                            0.99998                                                                                   \n",
       "3                                            0.99987                                                                                   \n",
       "4                                            0.99998                                                                                   \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 데이터 불러오기 및 확인\n",
    "df = pd.read_csv('../data/raw/BankChurners.csv')\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d311506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 전처리 (간단)\n",
    "# 타겟 컬럼: 'Attrition_Flag' (이탈: 'Attrited Customer', 유지: 'Existing Customer')\n",
    "df = df.copy()\n",
    "df['Attrition_Binary'] = (df['Attrition_Flag'] == 'Attrited Customer').astype(int)\n",
    "\n",
    "# 불필요한 컬럼 제거 (고객번호 등)\n",
    "drop_cols = [col for col in ['CLIENTNUM', 'Attrition_Flag', \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\"] if col in df.columns]\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "# 간단한 결측치 처리 (최빈값/평균 대체)\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "for col in df.select_dtypes(include=np.number).columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# 범주형 변수 원-핫 인코딩\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237da3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10127, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fac8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8101, 32) Test shape: (2026, 32)\n"
     ]
    }
   ],
   "source": [
    "# 4. 학습/테스트 데이터 분리\n",
    "X = df.drop('Attrition_Binary', axis=1)\n",
    "y = df['Attrition_Binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399ba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimjunseog/projects/skn-2nd-3team/venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogReg\n",
      "정확도: 0.8929\n",
      "ROC-AUC: 0.8993\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      1701\n",
      "           1       0.75      0.50      0.60       325\n",
      "\n",
      "    accuracy                           0.89      2026\n",
      "   macro avg       0.83      0.73      0.77      2026\n",
      "weighted avg       0.88      0.89      0.88      2026\n",
      "\n",
      "Model: DTree\n",
      "정확도: 0.9334\n",
      "ROC-AUC: 0.8707\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "Model: RF\n",
      "정확도: 0.9556\n",
      "ROC-AUC: 0.9838\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1701\n",
      "           1       0.94      0.78      0.85       325\n",
      "\n",
      "    accuracy                           0.96      2026\n",
      "   macro avg       0.95      0.88      0.91      2026\n",
      "weighted avg       0.95      0.96      0.95      2026\n",
      "\n",
      "Model: XGB\n",
      "정확도: 0.9664\n",
      "ROC-AUC: 0.9920\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1701\n",
      "           1       0.93      0.86      0.89       325\n",
      "\n",
      "    accuracy                           0.97      2026\n",
      "   macro avg       0.95      0.92      0.94      2026\n",
      "weighted avg       0.97      0.97      0.97      2026\n",
      "\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1302, number of negative: 6799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2058\n",
      "[LightGBM] [Info] Number of data points in the train set: 8101, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160721 -> initscore=-1.652874\n",
      "[LightGBM] [Info] Start training from score -1.652874\n",
      "Model: LGBM\n",
      "정확도: 0.9714\n",
      "ROC-AUC: 0.9924\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1701\n",
      "           1       0.94      0.88      0.91       325\n",
      "\n",
      "    accuracy                           0.97      2026\n",
      "   macro avg       0.96      0.93      0.95      2026\n",
      "weighted avg       0.97      0.97      0.97      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    ('LogReg', LogisticRegression(max_iter=1000)),\n",
    "    ('DTree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('RF', RandomForestClassifier(random_state=42)),\n",
    "    ('XGB', XGBClassifier(random_state=42, eval_metric='logloss')),\n",
    "    ('LGBM', LGBMClassifier(random_state=42)), \n",
    "    ('SVC', SVC(kernel='linear', probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"정확도: {acc:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}\")\n",
    "    print(\"\\n분류 리포트:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # 5. 베이스라인 모델 학습 (로지스틱 회귀)\n",
    "# model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1266f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8751\n",
      "ROC-AUC: 0.8126\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1701\n",
      "           1       0.68      0.42      0.52       325\n",
      "\n",
      "    accuracy                           0.88      2026\n",
      "   macro avg       0.79      0.69      0.72      2026\n",
      "weighted avg       0.86      0.88      0.86      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "roc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"정확도: {acc:.4f}\")\n",
    "print(f\"ROC-AUC: {roc:.4f}\")\n",
    "print(\"\\n분류 리포트:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b9719",
   "metadata": {},
   "source": [
    "## 간단한 결과 해석\n",
    "- 위 결과는 로지스틱 회귀를 활용한 이탈 예측의 베이스라인입니다.\n",
    "- 정확도(Accuracy)와 ROC-AUC, 분류 리포트를 참고해 모델의 기본 성능을 확인할 수 있습니다.\n",
    "- 더 나은 성능을 위해 추가적인 전처리, 피처 엔지니어링, 다양한 모델 실험이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8a7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1302, number of negative: 6799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2058\n",
      "[LightGBM] [Info] Number of data points in the train set: 8101, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160721 -> initscore=-1.652874\n",
      "[LightGBM] [Info] Start training from score -1.652874\n",
      "모델: LGBMClassifier\n",
      "정확도: 0.9714\n",
      "ROC-AUC: 0.9924\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1701\n",
      "           1       0.94      0.88      0.91       325\n",
      "\n",
      "    accuracy                           0.97      2026\n",
      "   macro avg       0.96      0.93      0.95      2026\n",
      "weighted avg       0.97      0.97      0.97      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 비교테스트(신병탁)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# 1. 사용할 모델들을 리스트로 정의\n",
    "models = [\n",
    "    # ('LogReg', LogisticRegression(max_iter=1000)),\n",
    "\t# ('DTree', DecisionTreeClassifier(random_state=42)),\n",
    "    # ('RF', RandomForestClassifier(random_state=42)),\n",
    "    # ('XGB', XGBClassifier(random_state=42, eval_metric='logloss')),\n",
    "\t('LGBM', LGBMClassifier(random_state=42)), \n",
    "\t# ('SVC', SVC(kernel='linear', probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "# 2. 반복문으로 학습 및 평가\n",
    "for name, model in models:\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\ty_pred = model.predict(X_test)\n",
    "\ty_proba = model.predict_proba(X_test)[:, 1]\n",
    "\tacc = accuracy_score(y_test, y_pred)\n",
    "\troc = roc_auc_score(y_test, y_proba)\n",
    "\tprint('모델:', model.__class__.__name__)\n",
    "\tprint(f\"정확도: {acc:.4f}\")\n",
    "\tprint(f\"ROC-AUC: {roc:.4f}\")\n",
    "\tprint(\"\\n분류 리포트:\")\n",
    "\tprint(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
